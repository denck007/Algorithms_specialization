# Course 2: Greedy Algorithms, Minimum Spanning Trees, and Dynamic Programming
I have found that it is really useful to keep a few data structures around, so I am starting to build up a little 'helpers' library.

## Week 1 Assignment: Greedy algorithms. Scheduling, minimum spanning trees, and Prim's algorithm
Implemented a greedy algorithm for scheduling jobs. Used 2 different cost functions, weight-length and weight/length. The weight/length is gaurenteed to be correct, but supprisingly the weight-length method did better than I expected it to and was only off by 2.6%. Obviously this error will not transfer to other problems, but iteresting that they are so similar on a random data set.

Implemented Prim's algorithm to find a minimum spanning tree. I actually thought this was pretty straight forward and really does not take much code to create. The main loop is really tight, and the loop over all the edges connected to a vertex is really straight forward. I ended up making some minor changes to my Heap data structure, to make comparisions simpler but it really only changed what the lists are initialized to.


## Week 2 Assignment: Kruskal's MST algorithm and applications to clustering
Question 1 is to implement Kruskals algorithm using union find. This was realitivly simple and mostly involved getting the uion find data structure to work properly.

Question 2 of this week was the hardest assignement yet, dealing with hamming distance between verticies. It is fairly easy to develop a working and correct solution, but the simple and obvious one is very slow. It ends up that flipping the problem and instead of looking for locations within a specified distance, modifiying the locations and seeing if the modified location exists is far more efficient. Bit fiddling would have been really helpful here, but I ran out of time. I extended the list object to be able to be hashed by creating a string of the data in the list. This works but is slow-ish, strings are immutable and we have to loop over every dimiension in the location. This ends up adding some large constants to the algorithm. 


## Week 3 Assignment: Huffman codes; Introduction to dynamic programming
Questions 1 and 2 are about generating Huffman codes for a dataset given frequencies of symbol use. This does not return the actual huffman code, but it could easily be generated by adding a method to the class. I believe that there are issues with the 8k and 10k length test cases, as those are the only ones to fail, and the solution comes out correct for the actual assignment.

Question 3 is an intro to dynamic programming. We find the maximum weight independent set of a path graph. This is a realitivly short and straight forword assignment

## Week 4 Assignmenet: Advanced dynamic programming: the knapsack problem, sequence alignment, and optimal binary search trees
Both programming problems are solving the knapsack problem, asking what the value of the optimal solution is.

The first dataset is small enough that we can compute every value using the method shown in the lecture.
The second dataset would take hours and gigabytes of memory to do this way.

The fast method I implemented uses a hash table using a tuple of  weight,item_number as keys. This method takes under 24 seconds to compute on my desktop, vs the estimated 2+ hours the naive method. The memory savings is 376x with the question 2 dataset. 
